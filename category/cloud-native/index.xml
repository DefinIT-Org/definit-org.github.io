<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cloud-Native on DefinIT</title><link>https://www.definit.co.uk/category/cloud-native/</link><description>Recent content in Cloud-Native on DefinIT</description><generator>Hugo</generator><language>en-gb</language><lastBuildDate>Mon, 13 Dec 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.definit.co.uk/category/cloud-native/index.xml" rel="self" type="application/rss+xml"/><item><title>Forwarding Tanzu Kubernetes Grid logs to vRealize Log Insight Cloud using the Fluent-bit Package</title><link>https://www.definit.co.uk/2021/12/forwarding-tanzu-kubernetes-grid-logs-to-vrealize-log-insight-cloud-using-the-fluent-bit-package/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2021/12/forwarding-tanzu-kubernetes-grid-logs-to-vrealize-log-insight-cloud-using-the-fluent-bit-package/</guid><description>&lt;p&gt;In my previous post I walked through &lt;a href="https://www.definit.co.uk/2021/12/ingress-ssl-and-dns-using-tkg-1.4-packages-on-tkgs-clusters/"&gt;
 configuring kubernetes ingress with automatically generated SSL certificates and DNS registration
&lt;/a&gt; using Tanzu Kubernetes Grid&amp;rsquo;s Packages. Another of the packaged applications available is Fluent-bit, which enables log forwarding from your Kubernetes cluster and workloads to a range of supported logging endpoints.&lt;/p&gt;
&lt;p&gt;There are a couple of tweaks required in order to forward logs to vRealize Automation Log Insight Cloud. We need to use the HTTP output in the Fluent Bit configuration to forward the logs as a JSON payload to the Log Insight API. We also need to append an authentication header with an API key, and configure some tags so that the Tanzu Kubnernetes Grid Content Pack will pick up the logs.&lt;/p&gt;</description></item><item><title>Ingress, SSL and DNS using TKG 1.4 Packages on TKGs Clusters</title><link>https://www.definit.co.uk/2021/12/ingress-ssl-and-dns-using-tkg-1.4-packages-on-tkgs-clusters/</link><pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2021/12/ingress-ssl-and-dns-using-tkg-1.4-packages-on-tkgs-clusters/</guid><description>&lt;p&gt;So, you&amp;rsquo;ve set up your shiny new Workload Management on vSphere, created a Namespace and deployed a cluster&amp;hellip;now what?! When you deploy a workload cluster from Workload Management on vSphere 7, it comes with basic functionality, but in order to start running workloads you will inevitably need to install additional tools. That&amp;rsquo;s where Tanzu&amp;rsquo;s Packages come into play.&lt;/p&gt;
&lt;p&gt;Tanzu&amp;rsquo;s User Managed Packages are based on a project called &lt;a href="https://github.com/vmware-tanzu/carvel" target="_blank"&gt;
 &lt;clr-icon shape="pop-out" size="12"&gt;&lt;/clr-icon&gt; Carvel
&lt;/a&gt; which:&lt;/p&gt;</description></item><item><title>Replacing Docker Desktop with VMware Fusion or Workstation</title><link>https://www.definit.co.uk/2021/09/replacing-docker-desktop-with-vmware-fusion-or-workstation/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2021/09/replacing-docker-desktop-with-vmware-fusion-or-workstation/</guid><description>&lt;p&gt;Just recently Docker announced some new pricing tiers for it&amp;rsquo;s almost ubiquitous Docker Desktop. I&amp;rsquo;m not going to opine much on this, time will tell whether this is a company saving move or not. Suffice to say that I work for a large company and would need a subscription to continue using Docker Desktop.&lt;/p&gt;
&lt;p&gt;The venerable &lt;a href="https://twitter.com/QuinnyPig" target="_blank"&gt;
 &lt;clr-icon shape="pop-out" size="12"&gt;&lt;/clr-icon&gt; Corey Quinn
&lt;/a&gt; was on the news like a flash, so I&amp;rsquo;ll let you &lt;a href="https://twitter.com/QuinnyPig/status/1432720164169076755" target="_blank"&gt;
 &lt;clr-icon shape="pop-out" size="12"&gt;&lt;/clr-icon&gt; read his thread
&lt;/a&gt; for some hard core &lt;del&gt;snark&lt;/del&gt; analysis.&lt;/p&gt;</description></item><item><title>Scheduling a restart of a Kubernetes Deployment using CronJobs</title><link>https://www.definit.co.uk/2021/04/scheduling-a-restart-of-a-kubernetes-deployment-using-cronjobs/</link><pubDate>Thu, 08 Apr 2021 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2021/04/scheduling-a-restart-of-a-kubernetes-deployment-using-cronjobs/</guid><description>&lt;p&gt;Most of my home network runs on my &lt;a href="https://www.definit.co.uk/2020/09/whats-in-your-kubernetes-home-lab/"&gt;
 Raspberry Pi Kubernetes cluster
&lt;/a&gt;, and for the most part it&amp;rsquo;s rock solid. However, applications being applications, sometimes they become less responsive than they should (or for example, when my Synology updates itself and reboots, any mounted NFS volumes can cause the running pods to degrade in performance). This isn&amp;rsquo;t an issue with service liveliness, which can be mitigated with a &lt;a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-a-liveness-command" target="_blank"&gt;
 &lt;clr-icon shape="pop-out" size="12"&gt;&lt;/clr-icon&gt; liveness probe
&lt;/a&gt; that restarts the pod if a service isn&amp;rsquo;t running.&lt;/p&gt;</description></item><item><title>Automatically adding Kubernetes Service DNS records to Microsoft DNS using CoreDNS and k8s_gateway</title><link>https://www.definit.co.uk/2020/12/automatically-adding-kubernetes-service-dns-records-to-microsoft-dns-using-coredns-and-k8s_gateway/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2020/12/automatically-adding-kubernetes-service-dns-records-to-microsoft-dns-using-coredns-and-k8s_gateway/</guid><description>&lt;p&gt;When I deploy a new service into a namespace, I need to create a new DNS record that makes it available. I&amp;rsquo;ve previously talked about using CoreDNS to host my lab DNS zones, but this is something different. I want to make a Kubernetes Service available using an existing Microsoft DNS server - which is already used by all the clients who would need to access the service.&lt;/p&gt;
&lt;p&gt;To do this I will create a delegated zone under my existing zone &lt;code&gt;cmbu.local&lt;/code&gt; that CoreDNS will be responsible for. Then I will use the &lt;code&gt;k8s_gateway&lt;/code&gt; plugin to automatically create records for Services provisioned within my zone.&lt;/p&gt;</description></item><item><title>Backing up Tanzu Kubernetes Grid (TKG) on vSphere Workloads to AWS with Velero</title><link>https://www.definit.co.uk/2020/10/backing-up-tanzu-kubernetes-grid-tkg-on-vsphere-workloads-to-aws-with-velero/</link><pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2020/10/backing-up-tanzu-kubernetes-grid-tkg-on-vsphere-workloads-to-aws-with-velero/</guid><description>&lt;p&gt;As more services go live on my Kubernetes clusters and more people start relying on them, I get nervous. For the most part, I try and keep my applications and configurations stateless - relying on &lt;code&gt;ConfigMaps&lt;/code&gt; for example to store application configuration. This means with a handful of YAML files in my Git repository I can restore everything to working order. Sometimes though, there&amp;rsquo;s no choice but to use a &lt;code&gt;PersistentVolume&lt;/code&gt; to provide some data persistance where you can&amp;rsquo;t capture it in a config file. This is where a backup of the cluster - and specifically the &lt;code&gt;PersistentVolume&lt;/code&gt; is really important.&lt;/p&gt;</description></item><item><title>What's in your Kubernetes Home Lab?</title><link>https://www.definit.co.uk/2020/09/whats-in-your-kubernetes-home-lab/</link><pubDate>Mon, 21 Sep 2020 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2020/09/whats-in-your-kubernetes-home-lab/</guid><description>&lt;p&gt;If you&amp;rsquo;re anything like me, your home lab is constantly changing, evolving, breaking, rebuilding. For the last year or so I&amp;rsquo;ve been running all my home kubernetes workloads on a Raspberry Pi cluster - and it&amp;rsquo;s been working really well!&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ve been through several iterations - for example firstly running on SD cards (tl;dr - it&amp;rsquo;s bad, they wear out really fast with Kubernetes on board!), then &lt;a href="https://www.definit.co.uk/2020/03/pxe-booting-raspberry-pi-4-with-synology-and-ubiquiti-edgerouter/"&gt;
 PxE booting them from my Synology
&lt;/a&gt; to it&amp;rsquo;s now current state of booting directly from SSDs. I&amp;rsquo;ve also moved from Raspberry Pi 3s to 4s, I&amp;rsquo;ve played around with stacking cluster cases before landing on the current rack-mount format.&lt;/p&gt;</description></item><item><title>PXE Booting Raspberry Pi 4 with Synology and Ubiquiti EdgeRouter</title><link>https://www.definit.co.uk/2020/03/pxe-booting-raspberry-pi-4-with-synology-and-ubiquiti-edgerouter/</link><pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2020/03/pxe-booting-raspberry-pi-4-with-synology-and-ubiquiti-edgerouter/</guid><description>&lt;p&gt;I love Raspbery Pis - I have done since they first released them, all the way up to the present iteration, the Raspberry Pi 4. They&amp;rsquo;re phenominal little bits of kit, endlessly hackable and because of their really low price, they open up computing to a huge number of people who otherwise wouldn&amp;rsquo;t get the opportunity.&lt;/p&gt;
&lt;p&gt;One of the irritating things, though, about running Raspberry Pis is that they typically boot from an SD card. SD cards are notorious for having high attrition rates, especially if you&amp;rsquo;re reading/writing to them regularly. Running a Kubernetes cluster on my Raspberry Pis is especially hard on the SD card because you&amp;rsquo;re not only running the system&amp;rsquo;s read and writes, but you&amp;rsquo;re also running containers and their I/O on the card.&lt;/p&gt;</description></item><item><title>Certified Kubernetes Administrator (CKA) Exam Experience</title><link>https://www.definit.co.uk/2020/02/certified-kubernetes-administrator-cka-exam-experience/</link><pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2020/02/certified-kubernetes-administrator-cka-exam-experience/</guid><description>&lt;p&gt;Since I started learning Kubernetes the Certified Kubernetes Administrator (CKA) exam has been a target for me, but it&amp;rsquo;s always seemed to be out of reach. The whole Kubernetes ecosystem is a vast and nebulous beast, with new projects rising to the fore all the time, and old projects fading from favour. The size and rapid development that make the field so interesting and powerful, are the same properties that make the learning curve so steep, and the entry bar so high.&lt;/p&gt;</description></item><item><title>Certified Kubernetes Security Specialist (CKS) Exam Experience</title><link>https://www.definit.co.uk/2020/02/certified-kubernetes-security-specialist-cks-exam-experience/</link><pubDate>Fri, 28 Feb 2020 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2020/02/certified-kubernetes-security-specialist-cks-exam-experience/</guid><description>&lt;p&gt;I&amp;rsquo;ve had the Certified Kubernetes Security Specialist exam booked for a long time - so long in fact that the exam voucher was due to expire at the end of January 2022! I figured I&amp;rsquo;d give it a go right at the start of January, work out how far off the mark I was and then aim to do the free retake before it expired at the end of the month.&lt;/p&gt;</description></item><item><title>Running CoreDNS for lab name resolution</title><link>https://www.definit.co.uk/2020/01/running-coredns-for-lab-name-resolution/</link><pubDate>Fri, 24 Jan 2020 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2020/01/running-coredns-for-lab-name-resolution/</guid><description>&lt;p&gt;Up until recently I&amp;rsquo;ve been running a Windows Server Core VM with Active Directory, DNS and Certificate Services deployed to provide some core features in my home lab. However, I&amp;rsquo;ve also been conscious that running a lab on old hardware doesn&amp;rsquo;t exactly have much in the way of green credentials. So, in an effort to reduce my carbon footprint (and electricity bill) I&amp;rsquo;ve been looking for ways to shut down my lab when it&amp;rsquo;s not in use.&lt;/p&gt;</description></item><item><title>Lab Guide - Kubernetes Load Balancer and Ingress with MetalLB and Contour</title><link>https://www.definit.co.uk/2019/08/lab-guide-kubernetes-load-balancer-and-ingress-with-metallb-and-contour/</link><pubDate>Fri, 02 Aug 2019 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2019/08/lab-guide-kubernetes-load-balancer-and-ingress-with-metallb-and-contour/</guid><description>&lt;p&gt;I run quite a few applications in Docker as part of my home network - there&amp;rsquo;s a small selection below, but at any one time there might be 10-15 more apps I&amp;rsquo;m playing around with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;plex - Streaming media server&lt;/li&gt;
&lt;li&gt;unifi - Ubiquiti Network Controller&lt;/li&gt;
&lt;li&gt;homebridge - Apple Homekit compatible smart home integration&lt;/li&gt;
&lt;li&gt;influxdb - Open source time series database&lt;/li&gt;
&lt;li&gt;grafana - Data visualization &amp;amp; Monitoring&lt;/li&gt;
&lt;li&gt;pihole - internet tracking and ad blocker&lt;/li&gt;
&lt;li&gt;vault - Hashicorp secret management&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Until recently a single PhotonOS VM with Docker was all I needed to run - everything shared the same host IP, stored it&amp;rsquo;s configuration locally or on an NFS mount and generally ran fine. However, my wife and kids have become more dependant on plex, and homebridge (which I use to control the air conditioning in my house), and if they&amp;rsquo;re down, it&amp;rsquo;s a problem. So, I embarked on a little project to provide some better availability, and learn a little in the process.&lt;/p&gt;</description></item><item><title>Lab Guide - Kubernetes and NSX-T Container Network Plugin - Step by Step</title><link>https://www.definit.co.uk/2019/06/lab-guide-kubernetes-and-nsx-t-container-network-plugin-step-by-step/</link><pubDate>Wed, 12 Jun 2019 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2019/06/lab-guide-kubernetes-and-nsx-t-container-network-plugin-step-by-step/</guid><description>&lt;p&gt;I’ve done a fair amount of work learning VMware PKS and NSX-T, but I wanted to
drop down a level and get more familiar with the inner workings for Kubernetes,
as well as explore some of the newer features that are exposed by the NSX
Container Plugin that are not yet in the PKS integrations.&lt;/p&gt;
&lt;p&gt;The NSX-T docs are…not great, I certainly don’t think you can work out the steps
required from the official &lt;a href="https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/com.vmware.nsxt.ncp_kubernetes.doc/GUID-FB641321-319D-41DC-9D16-37D6BA0BC0DE.html" target="_blank"&gt;
 &lt;clr-icon shape="pop-out" size="12"&gt;&lt;/clr-icon&gt; NCP installation
guide
&lt;/a&gt;
without a healthy dollop of background knowledge and familiarity with Kubernetes
and CNI. &lt;a href="https://networkinferno.net/preparing-a-node-for-kubernetes-and-nsx-ncp" target="_blank"&gt;
 &lt;clr-icon shape="pop-out" size="12"&gt;&lt;/clr-icon&gt; Anthony Burke published this
guide
&lt;/a&gt;
which is great, and I am lucky enough to be able to pick his brains on our
corporate slack.&lt;/p&gt;</description></item><item><title>Goodbye Wordpress, hello Hugo!</title><link>https://www.definit.co.uk/2019/04/goodbye-wordpress-hello-hugo/</link><pubDate>Thu, 11 Apr 2019 00:00:00 +0000</pubDate><guid>https://www.definit.co.uk/2019/04/goodbye-wordpress-hello-hugo/</guid><description>&lt;p&gt;When I started my blog back in May 2007 (12 years ago!) I was running Wordpress, then switched to DotNetNuke, then BlogEngine, then finally back to Wordpress - which I&amp;rsquo;ve used since 2010. Today I&amp;rsquo;ve cut over to a new architecture based on Hugo and hosted on AWS using a combination of Route53, Cloudfront and S3.&lt;/p&gt;
&lt;h2 id="why-the-change-if-it-aint-broke"&gt;Why the change? If it ain&amp;rsquo;t broke&amp;hellip; &lt;a class="anchor" href="#why-the-change-if-it-aint-broke"&gt;
 &lt;i class="fas fa-hashtag"&gt;&lt;/i&gt;
&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;You may well ask why I&amp;rsquo;ve made the move, or you may not&amp;hellip;I&amp;rsquo;m going to tell you anyway&amp;hellip;&lt;/p&gt;</description></item><item><title>Upgrading PKS with NSX-T from 1.0.x to 1.1</title><link>https://www.definit.co.uk/2018/06/upgrading-pks-with-nsx-t-from-1-0-x-to-1-1/</link><pubDate>Fri, 29 Jun 2018 19:31:52 +0000</pubDate><guid>https://www.definit.co.uk/2018/06/upgrading-pks-with-nsx-t-from-1-0-x-to-1-1/</guid><description>&lt;p&gt;&lt;!-- raw HTML omitted --&gt;Yesterday, Pivotal Container Service 1.1 dropped and, as it’s something I’ve been actively learning in my lab, I wanted to jump on the upgrade straight away. PKS with NSX-T is a really hot topic right now and I think it’s going to be a big part of the future CNA landscape.&lt;/p&gt;
&lt;p&gt;My Lab PKS 1.0.4 deployment is configured as a &amp;ldquo;NO-NAT with Logical Switch (NSX-T) Topology” as depicted in the diagram below (from the PKS documentation). My setup has these network characteristics:&lt;/p&gt;</description></item><item><title>Sam’s #VMworld 2017: Intro to NSX-T Architecture #NET1510BE and NSX-T and Kubernetes #NET1522BE</title><link>https://www.definit.co.uk/2017/09/sams-vmworld-2017-intro-to-nsx-t-architecture-net1510be-and-nsx-t-and-kubernetes-net1522be/</link><pubDate>Tue, 12 Sep 2017 11:23:13 +0000</pubDate><guid>https://www.definit.co.uk/2017/09/sams-vmworld-2017-intro-to-nsx-t-architecture-net1510be-and-nsx-t-and-kubernetes-net1522be/</guid><description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;It will be no surprise, given &lt;a href="https://www.definit.co.uk/2017/09/the-next-big-thing/" target="_blank"&gt;
 &lt;clr-icon shape="pop-out" size="12"&gt;&lt;/clr-icon&gt; my impending move to the VMware PSO NSX Practice
&lt;/a&gt;, that this morning I&amp;rsquo;ve been focussing on NSX-T. The two sessions I attended were the Introduction to NSX-T Architecture and Integrating NSX-T with Kubernetes. In a weird twist of scheduling, the Kubernetes session was before the introduction session, but it worked out OK.&lt;/p&gt;
&lt;p&gt;I found the Kubernetes session really enjoyable and really felt like the speakers delivered a great overview of the integration and how they work together. I was pleasantly surprised with how fami&lt;!-- raw HTML omitted --&gt;liar a lot of the concepts were, coming from an NSX-v and vRealize Automation background. It&amp;rsquo;s similar, but different! This is something I can really get my teeth into.&lt;/p&gt;</description></item><item><title>vRA7.2 and vSphere Integrated Containers</title><link>https://www.definit.co.uk/2016/12/vra7-2-and-vsphere-integrated-containers/</link><pubDate>Mon, 19 Dec 2016 15:28:40 +0000</pubDate><guid>https://www.definit.co.uk/2016/12/vra7-2-and-vsphere-integrated-containers/</guid><description>&lt;p&gt;&lt;!-- raw HTML omitted --&gt;One of the cool new features released with vRealize Automation 7.2 was the integration of VMware Admiral (container management) into the product, and recently VMware made version 1 of vSphere Integrated Containers generally available (GA), so I thought it was time I started playing around with the two.&lt;/p&gt;
&lt;p&gt;In this article I&amp;rsquo;m going to cover deploying VIC to my vSphere environment and then adding that host to the vRA 7.2 container management.&lt;/p&gt;</description></item></channel></rss>